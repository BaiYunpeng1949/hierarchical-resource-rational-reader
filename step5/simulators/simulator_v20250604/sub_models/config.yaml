simulator_name: 'step5'

rl:
  mode: simulate   # Options: train, continual_train, test, debug, simulate (run modules), and grid_test.

  train:
    total_timesteps: 100000000
    checkpoints_folder_name: 1012_text_reading_baseline_full_memory
    num_workers: 20   # Smaller than the server's number of processes: 16 - should not be the maximum capacity of the processors, otherwise the local memory will overflow.
    num_steps: 10000   # Don't change this parameter -- previously 5000
    batch_size: 1000  # We recommend using a `batch_size` that is a factor of `n_steps * n_envs` -- previously 500
    ent_coef: 0.03    # Entropy coefficient
    n_epochs: 10       # Number of epochs
    clip_range: 0.2   # Clipping range
    clip_range_vf: None   # Clipping range for the value function
    target_kl: 0.1    # Target kl
    learning_rate:   # Learning rate
      initial_value: 1e-5
      min_value: 1e-7
      threshold: 0.8
    gamma: 0.99    # 0.99
    device: 'cuda'     # 'cuda' for default
    save_freq: 10000000  # Save a checkpoint every 0.50 million steps

  test:
    num_episodes: 10000
    loaded_model_name: 'rl_model_70000000_steps'   
    continual_logs_name: 'PPO_89'
    dataset_for_testing: 'simulate'   # OPTIONS: 'test', 'train', 'simulate'
    grid_params:
      w_penalty_spec: [1, 20, 1]

simulate:
  num_episodes: 1             # Number of episodes to simulate per dataset instance
  rl_models:
    text_reader:
      env_name: TextReadingUnderTimePressureEnv
      checkpoints_folder_name: '0710_text_reading_under_time_pressure_v0604_04' # NOTE: '0710_text_reading_under_time_pressure_v0604_04' # The formal version I should use
      loaded_model_name: 'rl_model_200000000_steps' # NOTE: 'rl_model_200000000_steps' # The formal version I should use
    sentence_reader:
      env_name: SentenceReadingUnderTimePressureEnv           
      checkpoints_folder_name: '0910_sentence_reaidng_v091007' # NOTE: '0910_sentence_reaidng_v091007'  # The formal version I should use
      loaded_model_name: 'rl_model_30000000_steps'  # NOTE: 'rl_model_30000000_steps' # The formal version I should use
    word_recognizer:
      env_name: WordRecognitionEnv     
      checkpoints_folder_name: '0814_word_recognition_v0807'      # NOTE: '0814_word_recognition_v0807' # The formal version I should use
      loaded_model_name: 'rl_model_200000000_steps'                      # NOTE: 'rl_model_200000000_steps' # The formal version I should use

llm:
  use_aalto_openai_api: True
  API_key: "sk-proj-H1oYBOCwNe22E5Mgc0V4T3BlbkFJUcRwMP0goXMjO04NWk47"   # My personal key
  AALTO_OPENAI_API_KEY: b5de1b1587e04ee187293168b540136a                             # The Aalto University's key
  model: "gpt-4o"
  refresh_interval: 20
  max_num_requests: 10       # Maximum number of retries for each API call
  retry_delay: 20           # Time to wait between retries (in seconds)